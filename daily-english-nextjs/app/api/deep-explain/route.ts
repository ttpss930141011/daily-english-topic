import { NextRequest } from 'next/server'
import { GoogleGenerativeAI } from '@google/generative-ai'

// Initialize Gemini AI
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '')

interface DeepExplainRequest {
  text: string
  userLanguage: string
  context?: string
  difficulty?: 'beginner' | 'intermediate' | 'advanced'
}

function buildPrompt(text: string, userLanguage: string, context?: string, difficulty = 'intermediate'): string {
  const languageMap: Record<string, string> = {
    'zh-TW': 'ç¹é«”ä¸­æ–‡',
    'zh-CN': 'ç®€ä½“ä¸­æ–‡',
    'ja': 'æ—¥æœ¬èª',
    'ko': 'í•œêµ­ì–´',
    'en': 'English'
  }

  const targetLanguage = languageMap[userLanguage] || 'ç¹é«”ä¸­æ–‡'
  const difficultyMap: Record<string, string> = {
    beginner: 'åˆå­¸è€…',
    intermediate: 'ä¸­ç´š',
    advanced: 'é«˜ç´š'
  }

  return `ä½œç‚ºä¸€ä½ç¶“é©—è±å¯Œçš„è‹±èªæ•™å¸«ï¼Œè«‹é‡å°ä»¥ä¸‹æ–‡å­—æä¾›æ·±åº¦è§£é‡‹ï¼š

**è¦è§£é‡‹çš„æ–‡å­—ï¼š** "${text}"
**ä½¿ç”¨è€…èªè¨€ï¼š** ${targetLanguage}
**å­¸ç¿’ç¨‹åº¦ï¼š** ${difficultyMap[difficulty]}
${context ? `**ä¸Šä¸‹æ–‡ï¼š** "${context}"` : ''}

è«‹ä»¥${targetLanguage}æä¾›ä»¥ä¸‹å…§å®¹ï¼š

## ğŸ“– å­—é¢ç¿»è­¯
æä¾›ç›´æ¥çš„ç¿»è­¯å«ç¾©

## ğŸ“ ç”¨æ³•èªªæ˜
è§£é‡‹ä½•æ™‚åŠå¦‚ä½•ä½¿ç”¨é€™å€‹è©å½™æˆ–ç‰‡èª

## ğŸ’¡ ä¾‹å¥ç¤ºç¯„
æä¾› 2-3 å€‹ä¸åŒæƒ…å¢ƒä¸‹çš„è‡ªç„¶ä¾‹å¥ï¼Œä¸¦é™„ä¸Š${targetLanguage}ç¿»è­¯

## ğŸŒ æ–‡åŒ–èƒŒæ™¯
è§£é‡‹ä»»ä½•ç›¸é—œçš„æ–‡åŒ–èƒŒæ™¯æˆ–èªè¨€ç‰¹è‰²

## ğŸ“š èªæ³•é‡é»
ç›¸é—œçš„èªæ³•æ¨¡å¼å’Œè¦å‰‡

## ğŸ”— ç›¸é—œè¡¨é”
é¡ä¼¼çš„ç‰‡èªã€åŒç¾©è©æˆ–ç›¸é—œè¡¨é”æ–¹å¼

## ğŸ’­ å­¸ç¿’æŠ€å·§
è¨˜æ†¶æˆ–ç†è§£é€™å€‹è©å½™çš„å¯¦ç”¨æŠ€å·§

è«‹åƒä¸€ä½å‹å–„çš„è€å¸«ä¸€æ¨£ï¼Œç”¨æ•™è‚²æ€§ä½†æœ‰è¶£çš„æ–¹å¼ä¾†è§£é‡‹ï¼Œå¹«åŠ©å­¸ç”ŸçœŸæ­£ç†è§£å’ŒæŒæ¡é€™å€‹æ¦‚å¿µã€‚`
}

export async function POST(request: NextRequest) {
  try {
    // Check if Gemini API key is available
    if (!process.env.GEMINI_API_KEY) {
      console.error('Gemini API key not found')
      return new Response(
        JSON.stringify({ error: 'AI service not configured' }),
        { 
          status: 500,
          headers: { 'Content-Type': 'application/json' }
        }
      )
    }

    const body: DeepExplainRequest = await request.json()
    const { text, userLanguage = 'zh-TW', context, difficulty = 'intermediate' } = body

    if (!text || typeof text !== 'string') {
      return new Response(
        JSON.stringify({ error: 'Text parameter is required' }),
        { 
          status: 400,
          headers: { 'Content-Type': 'application/json' }
        }
      )
    }

    const cleanText = text.trim()
    if (cleanText.length === 0) {
      return new Response(
        JSON.stringify({ error: 'Text cannot be empty' }),
        { 
          status: 400,
          headers: { 'Content-Type': 'application/json' }
        }
      )
    }

    if (cleanText.length > 500) {
      return new Response(
        JSON.stringify({ error: 'Text too long (max 500 characters)' }),
        { 
          status: 400,
          headers: { 'Content-Type': 'application/json' }
        }
      )
    }

    // Build the prompt
    const prompt = buildPrompt(cleanText, userLanguage, context, difficulty)

    try {
      // Get the model
      const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' })

      // Generate content with streaming
      const result = await model.generateContentStream(prompt)

      // Create a readable stream for the response
      const encoder = new TextEncoder()
      const stream = new ReadableStream({
        async start(controller) {
          try {
            for await (const chunk of result.stream) {
              const chunkText = chunk.text()
              if (chunkText) {
                controller.enqueue(encoder.encode(chunkText))
              }
            }
            controller.close()
          } catch (error) {
            console.error('Streaming error:', error)
            controller.error(error)
          }
        }
      })

      return new Response(stream, {
        headers: {
          'Content-Type': 'text/plain; charset=utf-8',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
        },
      })

    } catch (genAIError) {
      console.error('Gemini AI error:', genAIError)
      
      // Fallback response if Gemini fails
      const fallbackResponse = `# æ·±åº¦è§£é‡‹ï¼š${cleanText}

å¾ˆæŠ±æ­‰ï¼ŒAI è§£é‡‹æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨ã€‚ä»¥ä¸‹æ˜¯åŸºæœ¬è³‡è¨Šï¼š

## ğŸ“– åŸºæœ¬ç¿»è­¯
"${cleanText}" çš„åŸºæœ¬å«ç¾©éœ€è¦é€²ä¸€æ­¥æŸ¥è©¢ã€‚

## ğŸ’¡ å­¸ç¿’å»ºè­°
1. å˜—è©¦åœ¨ä¸åŒèªå¢ƒä¸­ä½¿ç”¨é€™å€‹è©å½™
2. æŸ¥é–±è‹±è‹±å­—å…¸ç²å¾—æ›´æ·±å…¥çš„ç†è§£
3. å°‹æ‰¾æ›´å¤šç›¸é—œä¾‹å¥

è«‹ç¨å¾Œå†è©¦æˆ–ä½¿ç”¨å…¶ä»–å­¸ç¿’è³‡æºã€‚`

      return new Response(fallbackResponse, {
        headers: {
          'Content-Type': 'text/plain; charset=utf-8',
        },
      })
    }

  } catch (error) {
    console.error('Deep explain route error:', error)
    return new Response(
      JSON.stringify({ error: 'Internal server error' }),
      { 
        status: 500,
        headers: { 'Content-Type': 'application/json' }
      }
    )
  }
}